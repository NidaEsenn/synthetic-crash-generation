{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Day 1: Image Generation Pipeline\n\n**What this notebook does:**\n1. Installs dependencies on Colab's free GPU\n2. Parses a crash report into structured data (using Groq API)\n3. Generates a photorealistic dashcam image from the parsed scenario (using **SDXL**)\n\n**Requirements:**\n- Google Colab with GPU runtime (`Runtime → Change runtime type → T4 GPU`)\n- Groq API key (free at console.groq.com)\n- Project files uploaded to Google Drive\n\n**Model:** Stable Diffusion XL (SDXL) — 1024x1024 resolution, much better prompt adherence than SD 1.5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies (Colab already has torch + CUDA)\n!pip install -q diffusers>=0.25.0 transformers accelerate safetensors\n!pip install -q openai pydantic python-dotenv"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to access project files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project to Python path\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/tesla_crash_synth')\n",
    "\n",
    "# Verify imports work\n",
    "from config import CrashScenario, Weather, IncidentType\n",
    "from utils.parser import LLMParser\n",
    "from utils.image_generator import BasicImageGenerator\n",
    "print('All imports successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU is available\n",
    "import torch\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set API Key\n",
    "\n",
    "Enter your Groq API key below. Get one free at [console.groq.com](https://console.groq.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Option A: Paste your key directly (quick testing)\n",
    "os.environ['GROQ_API_KEY'] = 'YOUR_KEY_HERE'  # <-- Replace this\n",
    "\n",
    "# Option B: Or load from .env file on Drive\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv('/content/drive/MyDrive/tesla_crash_synth/.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Parse a Crash Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize parser\nparser = LLMParser()\n\n# Parse a crash report\nreport = \"Vehicle traveling 45mph on wet highway, hydroplaned into guardrail\"\nscenario = parser.parse(report)\n\n# Show parsed result\nprint(scenario.model_dump_json(indent=2))\nprint(f'\\n--- Image Prompt Sent to SDXL ---')\nprint(scenario.image_prompt)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 4: Generate Dashcam Image\n\nThis downloads the SDXL model (~6.5GB) on first run. After that it's cached.\n\nSDXL generates **1024x1024** images (4x more pixels than SD 1.5's 512x512) with much better prompt adherence."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image generator (downloads model on first run)\n",
    "generator = BasicImageGenerator()  # auto-detects CUDA on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate image from parsed scenario\n",
    "image = generator.generate_from_scenario(scenario)\n",
    "\n",
    "# Display in notebook\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Drive\n",
    "output_dir = '/content/drive/MyDrive/tesla_crash_synth/outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "image.save(f'{output_dir}/day1_hydroplane.png')\n",
    "print(f'Saved to {output_dir}/day1_hydroplane.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Batch Generate Multiple Scenarios\n",
    "\n",
    "Let's test the full pipeline with different crash reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "reports = [\n    \"Vehicle traveling 45mph on wet highway, hydroplaned into guardrail\",\n    \"Car rear-ended truck at stoplight in clear weather\",\n    \"Pedestrian crossed outside crosswalk at night, struck by vehicle going 25mph\",\n    \"Side impact at intersection, vehicle ran red light at 35mph\",\n]\n\nfor i, report in enumerate(reports):\n    print(f'\\n{\"=\"*60}')\n    print(f'Report {i+1}: {report}')\n    \n    # Parse\n    scenario = parser.parse(report)\n    print(f'Parsed: {scenario.incident_type}, {scenario.weather}, {scenario.ego_speed_mps:.1f} m/s')\n    print(f'SD Prompt: {scenario.image_prompt[:100]}...')\n    \n    # Generate\n    image = generator.generate_from_scenario(scenario)\n    \n    # Save\n    path = f'{output_dir}/day1_test_{i}.png'\n    image.save(path)\n    print(f'Saved: {path}')\n    \n    # Display\n    display(image)\n\nprint(f'\\nDone! {len(reports)} images saved to {output_dir}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "If everything worked, you should have:\n",
    "- 4 dashcam images in `outputs/` on your Drive\n",
    "- Each matching its crash report description (weather, road type, incident)\n",
    "\n",
    "**Next step:** Day 2 — ControlNet for depth-controlled scene composition"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}